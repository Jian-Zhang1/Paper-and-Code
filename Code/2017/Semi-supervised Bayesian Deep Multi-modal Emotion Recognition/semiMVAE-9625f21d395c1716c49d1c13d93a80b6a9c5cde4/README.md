# Code for paper “Semi-supervised Bayesian Deep Multi-modal Emotion Recognition”
> - Paper: [Semi-supervised Bayesian Deep Multi-modal Emotion Recognition](https://arxiv.org/abs/1704.07548)
> - Authors: Changde Du, Changying Du, Jinpeng Li, Wei-long Zheng, Bao-liang Lu, Huiguang He

Implements the semi-supervised multi-view variational autoencoder (semiMVAE) in TensorFlow (python).

## Dependencies

- TensorFlow 1.0
- prettytensor
- numpy
- scipy

## Datasets

- [SEED: A dataset for emotion recognition using EEG signals](http://bcmi.sjtu.edu.cn/~seed/index.html)
- [DEAP: A database for emotion analysis using physiological signals](http://www.eecs.qmul.ac.uk/mmv/datasets/deap/index.html)

## Usage

- run the file semiMVAE.py directly. 

## Cite

Please cite our paper if you use this code in your own work:

```
@article{du2017semi,
  title={Semi-supervised Bayesian Deep Multi-modal Emotion Recognition},
  author={Du, Changde and Du, Changying and Li, Jinpeng and Zheng, Wei-long and Lu, Bao-liang and He, Huiguang},
  journal={arXiv preprint arXiv:1704.07548},
  year={2017}
}
```

## Credits

1. [semisupervised_vae](https://github.com/saemundsson/semisupervised_vae)
2. [Sharing deep generative representation for perceived image reconstruction from human brain activity](https://arxiv.org/pdf/1704.07575.pdf)

